{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of outputs are [[1464615 1587516]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Input Layer\n",
    "inputData = tf.constant([[100,150]])\n",
    "\n",
    "# Hidden Layer 1\n",
    "W1 = tf.constant([[5,10,15,20],[25,30,35,40]])\n",
    "b1 = tf.constant([[17,19,21,23]])\n",
    "\n",
    "H1 = tf.matmul(inputData,W1)+b1\n",
    "H1_Activation = H1 # Linear Activation\n",
    "\n",
    "# Output Layer\n",
    "W2 = tf.constant([[30,35],[40,45],[70,75],[80,85]])\n",
    "b2 = tf.constant([[35,36]])\n",
    "\n",
    "H2 = tf.matmul(H1_Activation,W2)+b2\n",
    "H2_Activation = H2 # Linear Activation\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('The values of outputs are',sess.run(H2_Activation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, cost:0.02385\n",
      "Epoch:10, cost:0.02360\n",
      "Epoch:20, cost:0.02336\n",
      "Epoch:30, cost:0.02314\n",
      "Epoch:40, cost:0.02294\n",
      "Epoch:50, cost:0.02275\n",
      "Epoch:60, cost:0.02257\n",
      "Epoch:70, cost:0.02241\n",
      "Epoch:80, cost:0.02225\n",
      "Epoch:90, cost:0.02211\n",
      "\n",
      "The input is  [0 0]\n",
      "The true output is  [0]\n",
      "The computed output is  0.033769593\n",
      "The squared error is  0.0011403854\n",
      "\n",
      "The input is  [1 0]\n",
      "The true output is  [1]\n",
      "The computed output is  0.971751\n",
      "The squared error is  0.0007980074\n",
      "\n",
      "The input is  [0 1]\n",
      "The true output is  [1]\n",
      "The computed output is  0.99025947\n",
      "The squared error is  9.4877956e-05\n",
      "\n",
      "The input is  [1 1]\n",
      "The true output is  [0]\n",
      "The computed output is  0.015018627\n",
      "The squared error is  0.00022555915\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "x_data = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y_data = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Constants\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "n_input, n_hidden, n_output = 2,3,1\n",
    "\n",
    "# Input Layer\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Hidden Layer 1\n",
    "W1 = tf.Variable([[-4.,-6.,-5.],[3.,6.,4.]],name='Weight1')\n",
    "b1 = tf.Variable([[-2.,3.,-2.]],name='Bias1')\n",
    "\n",
    "H1 = tf.matmul(X,W1)+b1\n",
    "H1_Activation = tf.sigmoid(H1)\n",
    "\n",
    "# Output Layer\n",
    "W2 = tf.Variable([[5.],[-9.],[7.]],name='Weight2')\n",
    "b2 = tf.Variable([[4.]],name='Bias2')\n",
    "\n",
    "output = tf.matmul(H1_Activation,W2)+b2\n",
    "output_Activation = tf.sigmoid(output)\n",
    "\n",
    "# Cost Function and Optimizer\n",
    "# Cost = Cross entropy\n",
    "# Optimizer = Gradient Descent\n",
    "cost = tf.reduce_mean(-Y*tf.log(output_Activation)-(1-Y)*tf.log(1-output_Activation))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(epochs):\n",
    "        sess.run(optimizer,feed_dict={X:x_data,Y:y_data})\n",
    "        \n",
    "        if step%10 == 0:\n",
    "            print(\"Epoch:%d, cost:%.5f\"%(step,sess.run(cost,feed_dict={X:x_data,Y:y_data})))\n",
    "            #print(H1_Activation)\n",
    "    \n",
    "    for i in range(len(y_data)):\n",
    "        err = tf.reduce_mean(tf.squared_difference(\n",
    "            tf.cast(y_data[i],tf.float32),\n",
    "            sess.run(output_Activation,feed_dict={X:x_data[i:i+1]})))\n",
    "        \n",
    "        print()\n",
    "        print('The input is ',x_data[i])\n",
    "        print('The true output is ',y_data[i])\n",
    "        print('The computed output is ',sess.run(tf.reduce_mean(\n",
    "            output_Activation),feed_dict={X:x_data[i:i+1]}))\n",
    "        print('The squared error is ',sess.run(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "    gre   gpa  rank\n",
      "0  380  3.61     3\n",
      "1  660  3.67     3\n",
      "2  800  4.00     1\n",
      "3  640  3.19     4\n",
      "4  520  2.93     4\n",
      "\n",
      "Scaled features\n",
      " [[0.27586207 0.77586207 0.66666667]\n",
      " [0.75862069 0.81034483 0.66666667]\n",
      " [1.         1.         0.        ]\n",
      " [0.72413793 0.53448276 1.        ]\n",
      " [0.51724138 0.38505747 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shijizhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Features data preprocessing\n",
    "data = pd.read_csv('Admissions.csv')\n",
    "\n",
    "features = data[['gre','gpa','rank']]\n",
    "featuresScale = preprocessing.minmax_scale(features)\n",
    "\n",
    "print('Original features\\n',features[0:5])\n",
    "print()\n",
    "print('Scaled features\\n',featuresScale[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels\n",
      " 0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: admit, dtype: int64\n",
      "\n",
      "One hot labels\n",
      " [[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Label Preprocessing\n",
    "labels = data['admit']\n",
    "\n",
    "one_hot = np.zeros(shape=(len(labels),2))\n",
    "for i in range(len(labels)):\n",
    "    # [1,0] means admitted, [0,1] means not admitted\n",
    "    one_hot[i,(1-labels[i])]=1\n",
    "\n",
    "print('Original labels\\n',labels[0:5])\n",
    "print()\n",
    "print('One hot labels\\n',one_hot[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    featuresScale, one_hot, test_size=0.3, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nodes number in hidden layer:  1\n",
      "Epoch:0, acc:0.67500, cost:0.64902\n",
      "Epoch:50, acc:0.70833, cost:0.57035\n",
      "Epoch:100, acc:0.71667, cost:0.57007\n",
      "\n",
      "Nodes number in hidden layer:  2\n",
      "Epoch:0, acc:0.67500, cost:0.65350\n",
      "Epoch:50, acc:0.67500, cost:0.62157\n",
      "Epoch:100, acc:0.67500, cost:0.62157\n",
      "\n",
      "Nodes number in hidden layer:  3\n",
      "Epoch:0, acc:0.67500, cost:0.65879\n",
      "Epoch:50, acc:0.71667, cost:0.56774\n",
      "Epoch:100, acc:0.71667, cost:0.56701\n",
      "\n",
      "Nodes number in hidden layer:  4\n",
      "Epoch:0, acc:0.67500, cost:0.64994\n",
      "Epoch:50, acc:0.73333, cost:0.56987\n",
      "Epoch:100, acc:0.71667, cost:0.56786\n",
      "\n",
      "Nodes number in hidden layer:  5\n",
      "Epoch:0, acc:0.67500, cost:0.64921\n",
      "Epoch:50, acc:0.71667, cost:0.57014\n",
      "Epoch:100, acc:0.71667, cost:0.56982\n",
      "\n",
      "Nodes number in hidden layer:  6\n",
      "Epoch:0, acc:0.67500, cost:0.61641\n",
      "Epoch:50, acc:0.70833, cost:0.56281\n",
      "Epoch:100, acc:0.71667, cost:0.56081\n",
      "\n",
      "Nodes number in hidden layer:  7\n",
      "Epoch:0, acc:0.68333, cost:0.64137\n",
      "Epoch:50, acc:0.74167, cost:0.56650\n",
      "Epoch:100, acc:0.72500, cost:0.56277\n",
      "\n",
      "Nodes number in hidden layer:  8\n",
      "Epoch:0, acc:0.67500, cost:0.65238\n",
      "Epoch:50, acc:0.70833, cost:0.56735\n",
      "Epoch:100, acc:0.69167, cost:0.56474\n",
      "\n",
      "Nodes number in hidden layer:  9\n",
      "Epoch:0, acc:0.67500, cost:0.59733\n",
      "Epoch:50, acc:0.70000, cost:0.56474\n",
      "Epoch:100, acc:0.70000, cost:0.56362\n",
      "\n",
      "Nodes number in hidden layer:  10\n",
      "Epoch:0, acc:0.67500, cost:0.64983\n",
      "Epoch:50, acc:0.70833, cost:0.56403\n",
      "Epoch:100, acc:0.70833, cost:0.56135\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "learning_rate = 0.01\n",
    "epochs = 101\n",
    "n_input, n_output = 3,2\n",
    "parameter_set = []   # Used to save weights and biases in each run\n",
    "\n",
    "for n_hidden in range(1,11):\n",
    "    # Reset the graph before next run\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Input Layer\n",
    "    X = tf.placeholder(tf.float32)\n",
    "    Y = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Hidden Layer 1\n",
    "    W1 = tf.Variable(tf.random_uniform([n_input,n_hidden],-1.0,1.0),name='Weight1')\n",
    "    b1 = tf.Variable(tf.zeros([n_hidden]),name='Bias1')\n",
    "    \n",
    "    H1 = tf.matmul(X,W1)+b1\n",
    "    H1_Activation = tf.nn.relu(H1)\n",
    "    \n",
    "    # Output Layer\n",
    "    W2 = tf.Variable(tf.random_uniform([n_hidden,n_output],-1.0,1.0),name='Weight2')\n",
    "    b2 = tf.Variable(tf.zeros([n_output]),name='Bias2')\n",
    "    \n",
    "    output = tf.matmul(H1_Activation,W2)+b2\n",
    "    predict = tf.argmax(output,axis=1)\n",
    "    \n",
    "    # Cost Function and Optimizer\n",
    "    # Cost = Cross entropy\n",
    "    # Optimizer = Gradient Descent\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y,logits=output))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print()\n",
    "        print('Nodes number in hidden layer: ',n_hidden)\n",
    "        sess.run(init)\n",
    "        \n",
    "        for step in range(epochs):\n",
    "            cst_all = 0\n",
    "            for i in range(len(train_X)):\n",
    "                [op,cst] = sess.run([optimizer,cost],\n",
    "                                     feed_dict={X:train_X[i:i+20],Y:train_Y[i:i+20]})\n",
    "                \n",
    "                cst_all += cst\n",
    "                \n",
    "            cst_all = cst_all/len(train_X)\n",
    "            test_accuracy = np.mean(np.argmax(test_Y,axis=1)==\n",
    "                                   sess.run(predict,feed_dict={X:test_X}))\n",
    "            \n",
    "            \n",
    "            if step%50 == 0:\n",
    "                print(\"Epoch:%d, acc:%.5f, cost:%.5f\"\n",
    "                      %(step, test_accuracy, cst_all))\n",
    "        \n",
    "        tvars = tf.trainable_variables()\n",
    "        tvars_vals = sess.run(tvars)\n",
    "        \n",
    "        # Save the name of the variable alongside its value in a dictionary\n",
    "        parameters = {var.name:val for var, val in zip(tvars, tvars_vals)}\n",
    "        parameter_set.append(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the highest accuracy occurs when n_hidden = 7. The weights and biases of that neural network model are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight1:0\n",
      " [[-0.4418435   0.7490924   1.129238   -0.06484197 -0.7350185   0.82714206\n",
      "   0.28770313]\n",
      " [-0.87327003 -1.0241653   0.0476774   0.6508952  -1.0116814  -0.9289226\n",
      "  -0.9616844 ]\n",
      " [ 0.25594115 -0.99001855 -0.64674044 -0.84080595  1.1995713  -0.25539625\n",
      "   0.1302991 ]]\n",
      "Bias1:0\n",
      " [ 0.         -0.04817996 -0.14377616  0.15156877  0.17747189  0.04525077\n",
      "  0.77388877]\n",
      "Weight2:0\n",
      " [[-0.623121    0.31207705]\n",
      " [ 1.1367003  -0.86709774]\n",
      " [ 1.1714671   0.2767058 ]\n",
      " [ 0.15580466 -0.96104336]\n",
      " [-0.37090987  1.1774316 ]\n",
      " [ 0.8475938   0.20807974]\n",
      " [-0.78055274  0.30731335]]\n",
      "Bias2:0\n",
      " [-0.40363762  0.40363762]\n"
     ]
    }
   ],
   "source": [
    "for key,val in parameter_set[6].items():\n",
    "    print('%s\\n'%key,val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "       TV  Radio  Newspaper\n",
      "0  230.1   37.8       69.2\n",
      "1   44.5   39.3       45.1\n",
      "2   17.2   45.9       69.3\n",
      "3  151.5   41.3       58.5\n",
      "4  180.8   10.8       58.4\n",
      "\n",
      "Scaled features\n",
      " [[0.77578627 0.76209677 0.60598065]\n",
      " [0.1481231  0.79233871 0.39401935]\n",
      " [0.0557998  0.92540323 0.60686016]\n",
      " [0.50997633 0.83266129 0.51187335]\n",
      " [0.60906324 0.21774194 0.51099384]]\n",
      "\n",
      "Labels\n",
      " 0    22.1\n",
      "1    10.4\n",
      "2     9.3\n",
      "3    18.5\n",
      "4    12.9\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Features data preprocessing\n",
    "data = pd.read_csv('Advertising.csv')\n",
    "\n",
    "features = data[['TV','Radio','Newspaper']]\n",
    "labels = data['Sales']\n",
    "featuresScale = preprocessing.minmax_scale(features)\n",
    "\n",
    "print('Original features\\n',features[0:5])\n",
    "print()\n",
    "print('Scaled features\\n',featuresScale[0:5])\n",
    "print()\n",
    "print('Labels\\n',labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    featuresScale, labels, test_size=0.3, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nodes number in hidden layer:  1\n",
      "Epoch:0, RMSE:5.47377, cost:36.26152\n",
      "Epoch:50, RMSE:5.50632, cost:25.10260\n",
      "Epoch:100, RMSE:5.50764, cost:25.10469\n",
      "\n",
      "Nodes number in hidden layer:  2\n",
      "Epoch:0, RMSE:5.54996, cost:33.19550\n",
      "Epoch:50, RMSE:5.50741, cost:25.09882\n",
      "Epoch:100, RMSE:5.50784, cost:25.10031\n",
      "\n",
      "Nodes number in hidden layer:  3\n",
      "Epoch:0, RMSE:5.41994, cost:34.88515\n",
      "Epoch:50, RMSE:5.50501, cost:25.10092\n",
      "Epoch:100, RMSE:5.50604, cost:25.10274\n",
      "\n",
      "Nodes number in hidden layer:  4\n",
      "Epoch:0, RMSE:5.51146, cost:35.25474\n",
      "Epoch:50, RMSE:5.50821, cost:25.10086\n",
      "Epoch:100, RMSE:5.50793, cost:25.10323\n",
      "\n",
      "Nodes number in hidden layer:  5\n",
      "Epoch:0, RMSE:5.51502, cost:33.12718\n",
      "Epoch:50, RMSE:5.50290, cost:25.09880\n",
      "Epoch:100, RMSE:5.50339, cost:25.10041\n",
      "\n",
      "Nodes number in hidden layer:  6\n",
      "Epoch:0, RMSE:5.45617, cost:36.29402\n",
      "Epoch:50, RMSE:5.50378, cost:25.10164\n",
      "Epoch:100, RMSE:5.50406, cost:25.10375\n",
      "\n",
      "Nodes number in hidden layer:  7\n",
      "Epoch:0, RMSE:5.46046, cost:32.55410\n",
      "Epoch:50, RMSE:5.50557, cost:25.09839\n",
      "Epoch:100, RMSE:5.50534, cost:25.09990\n",
      "\n",
      "Nodes number in hidden layer:  8\n",
      "Epoch:0, RMSE:5.42330, cost:31.42747\n",
      "Epoch:50, RMSE:5.50694, cost:25.09761\n",
      "Epoch:100, RMSE:5.50706, cost:25.09888\n",
      "\n",
      "Nodes number in hidden layer:  9\n",
      "Epoch:0, RMSE:5.44109, cost:31.13673\n",
      "Epoch:50, RMSE:5.50503, cost:25.09723\n",
      "Epoch:100, RMSE:5.50310, cost:25.09828\n",
      "\n",
      "Nodes number in hidden layer:  10\n",
      "Epoch:0, RMSE:5.41793, cost:35.34969\n",
      "Epoch:50, RMSE:5.50204, cost:25.10116\n",
      "Epoch:100, RMSE:5.50444, cost:25.10313\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "learning_rate = 0.01\n",
    "epochs = 101\n",
    "n_input, n_output = 3,1\n",
    "parameter_set = []   # Used to save weights and biases in each run\n",
    "\n",
    "for n_hidden in range(1,11):\n",
    "    # Reset the graph before next run\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Input Layer\n",
    "    X = tf.placeholder(tf.float32)\n",
    "    Y = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Hidden Layer 1\n",
    "    W1 = tf.Variable(tf.random_uniform([n_input,n_hidden],-1.0,1.0),name='Weight1')\n",
    "    b1 = tf.Variable(tf.zeros([n_hidden]),name='Bias1')\n",
    "    \n",
    "    H1 = tf.matmul(X,W1)+b1\n",
    "    H1_Activation = tf.nn.relu(H1)\n",
    "    \n",
    "    # Output Layer\n",
    "    W2 = tf.Variable(tf.random_uniform([n_hidden,n_output],-1.0,1.0),name='Weight2')\n",
    "    b2 = tf.Variable(tf.zeros([n_output]),name='Bias2')\n",
    "    \n",
    "    output = tf.matmul(H1_Activation,W2)+b2\n",
    "    \n",
    "    # Cost Function and Optimizer\n",
    "    # Cost = Mean Squared Error\n",
    "    # Optimizer = Gradient Descent\n",
    "    cost = tf.reduce_mean(tf.squared_difference(Y,output))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print()\n",
    "        print('Nodes number in hidden layer: ',n_hidden)\n",
    "        sess.run(init)\n",
    "        \n",
    "        for step in range(epochs):\n",
    "            cst_all = 0\n",
    "            for i in range(len(train_X)):\n",
    "                [op,cst] = sess.run([optimizer,cost],\n",
    "                                     feed_dict={X:train_X[i:i+20],Y:train_Y[i:i+20]})\n",
    "                \n",
    "                cst_all += cst\n",
    "                \n",
    "            cst_all = cst_all/len(train_X)\n",
    "            RMSE = tf.sqrt(tf.reduce_mean(tf.squared_difference(test_Y,\n",
    "                                                 sess.run(output,feed_dict={X:test_X}))))\n",
    "            \n",
    "            if step%50 == 0:\n",
    "                print(\"Epoch:%d, RMSE:%.5f, cost:%.5f\"\n",
    "                      %(step, sess.run(RMSE), cst_all))\n",
    "        \n",
    "        tvars = tf.trainable_variables()\n",
    "        tvars_vals = sess.run(tvars)\n",
    "        \n",
    "        # Save the name of the variable alongside its value in a dictionary\n",
    "        parameters = {var.name:val for var, val in zip(tvars, tvars_vals)}\n",
    "        parameter_set.append(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the lowest test RMSE occurs when n_hidden = 9. The weights and biases of that neural network model are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight1:0\n",
      " [[ 0.5146249   0.49574792  0.64518815  0.5259637  -0.65452456 -0.87737054\n",
      "   0.19713464 -0.9427813  -0.21480758]\n",
      " [ 0.50300485  0.25255957 -0.21612377 -0.13811685 -0.20818281 -0.45342895\n",
      "  -0.31308943 -0.68188983  0.40613502]\n",
      " [ 0.42019966 -0.22225115  0.12857616 -0.84278184 -0.84466887  0.61545116\n",
      "   0.1266887   0.93728274 -0.17681837]]\n",
      "Bias1:0\n",
      " [-1.8874505e-01 -4.2021748e-01 -2.3129682e-01 -6.1201084e-02\n",
      "  0.0000000e+00 -9.6538372e-02  2.9072924e+00 -2.0517432e-04\n",
      "  2.4742637e+00]\n",
      "Weight2:0\n",
      " [[ 0.21458986]\n",
      " [-0.24147332]\n",
      " [-0.00415528]\n",
      " [ 0.0226226 ]\n",
      " [ 0.75259805]\n",
      " [-0.5844283 ]\n",
      " [ 2.4066591 ]\n",
      " [ 0.49551877]\n",
      " [ 2.0414302 ]]\n",
      "Bias2:0\n",
      " [2.4787188]\n"
     ]
    }
   ],
   "source": [
    "for key,val in parameter_set[8].items():\n",
    "    print('%s\\n'%key,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
